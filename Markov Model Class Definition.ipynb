{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Model class definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook defines a constructor for a Markov model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put all the imports at the beginning\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the Markov model class, I also need a MarkovState class. The MarkovState class will contain the information about the state following one or more transitional steps from the MM.\n",
    "\n",
    "This class needs the following data:\n",
    "\n",
    "1. An index (index_ls) of the states considered in the MarkovState\n",
    "\n",
    "2. A (logged) probabilistic distribution of the current state (currentState_ar)\n",
    "\n",
    "3. A structure containing the historical paths to each node in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovState:\n",
    "    \n",
    "    def __init__(self, index_ls, currentLogState_ar, paths_ls):\n",
    "        \n",
    "        self.myIndex_ls=index_ls\n",
    "        self.myCurrentLogState_ar=currentLogState_ar\n",
    "        self.myPaths_ls=paths_ls\n",
    "        \n",
    "    def get_log_current_state_distribution(self):\n",
    "        return self.myCurrentLogState_ar\n",
    "    \n",
    "    def get_current_state_distribution(self):\n",
    "        return np.exp(self.myCurrentLogState_ar)\n",
    "    \n",
    "    def get_index(self):\n",
    "        return self.myIndex_ls\n",
    "    \n",
    "    def get_path_list(self):\n",
    "        return self.myPaths_ls\n",
    "        \n",
    "    def most_likely_path(self, state):\n",
    "        '''\n",
    "        Find the most likely path to the current state,\n",
    "        as found from the path history\n",
    "        '''\n",
    "        stateIndex_i=self.myIndex_ls.index(state)\n",
    "        return [self.myIndex_ls[row[stateIndex_i]] for row in self.myPaths_ls] + [state]\n",
    "    \n",
    "    def most_likely_state(self, n=1):\n",
    "        '''\n",
    "        Return the n most likely states to have ended up in.\n",
    "        '''\n",
    "        return [y[1] for y in sorted([x for x in zip(self.get_current_state_distribution(), self.get_index())],\n",
    "                                     reverse=True)\n",
    "               ][:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it's not the only way of defining a Markov model, for the moment, I'm going to do the definition by taking arguments in the constructor that represent a distribution of transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovModel:\n",
    "    \n",
    "    def __init__(self, transitions_ls, initialStates_ls=[], extraStates_ls=[]):\n",
    "        '''\n",
    "        Take a list of initial states, and a list of pairs of transitions\n",
    "        between states. Create a Markov model based on the distribution of\n",
    "        initial states, and distribution of transitions.\n",
    "        \n",
    "        extraStates_ls is a list of additional states which do not appear\n",
    "        in the two lists initialStates_ls and transitions_ls.\n",
    "        \n",
    "        If initialStates_ls is empty, assume an equal distribution over all\n",
    "        the states obtained from the transitions and the extra states.\n",
    "        '''\n",
    "        \n",
    "        # First, build the list of all states in the model\n",
    "        self.stateIndex_ls=list({x for x in initialStates_ls}. \\\n",
    "                                 union({x for (x, y) in transitions_ls}). \\\n",
    "                                 union({y for (x, y) in transitions_ls}). \\\n",
    "                                 union(set(extraStates_ls)))\n",
    "        self.stateIndex_ls.sort() # just for aesthetics\n",
    "\n",
    "        # Now build an array that contains the initial states\n",
    "        if initialStates_ls==[]:\n",
    "            initialStates_ls=self.stateIndex_ls        \n",
    "        self.initialState_ar=np.array([initialStates_ls.count(state) \n",
    "                                       for state in self.stateIndex_ls])\n",
    "        # and normalise the values so the prob.s sum to 1\n",
    "        self.initialState_ar=self.initialState_ar/np.sum(self.initialState_ar)\n",
    "        \n",
    "        # Now build an array that encodes the transitions\n",
    "        self.transitionMatrix_ar=np.zeros((len(self.stateIndex_ls), \n",
    "                                           len(self.stateIndex_ls)), \n",
    "                                          dtype=np.float)  # Normally int, but we're\n",
    "                                                           # going to normalise\n",
    "        for (x, y) in transitions_ls:\n",
    "            self.transitionMatrix_ar[self.stateIndex_ls.index(x)][self.stateIndex_ls.index(y)]+=1\n",
    "        for (i, r) in enumerate(self.transitionMatrix_ar):\n",
    "            if np.sum(self.transitionMatrix_ar[i])>0:\n",
    "                self.transitionMatrix_ar[i]=self.transitionMatrix_ar[i]/sum(self.transitionMatrix_ar[i])\n",
    "                \n",
    "        # Take the log of the transition matrix to make\n",
    "        # calculations more accurate\n",
    "        self.logTransitionMatrix_ar=np.log(self.transitionMatrix_ar)\n",
    "        \n",
    "        # Same for the initial states:\n",
    "        self.logInitialState_ar=np.log(self.initialState_ar)\n",
    "        \n",
    "\n",
    "    def create_markov_state(self, statesIn_ls):\n",
    "        '''\n",
    "        Helper function to convert a list of states\n",
    "        to a MarkovState object. Usually used as the\n",
    "        first step of input to the apply method.\n",
    "        '''\n",
    "        \n",
    "        initialStatesDist_ls=[statesIn_ls.count(s) for s in self.stateIndex_ls]\n",
    "        dist_ar=np.array(initialStatesDist_ls)/np.sum(initialStatesDist_ls)\n",
    "        \n",
    "        return MarkovState(self.stateIndex_ls,\n",
    "                           np.log(dist_ar),\n",
    "                           [])\n",
    "        \n",
    "    def apply_1(self, stateIn_ms):\n",
    "        '''\n",
    "        Helper function to apply: applies the transition matrix\n",
    "        for self to stateIn_ms. Returns the pair of the log \n",
    "        distribution of outputs and the previous state from \n",
    "        which the next state is arrived at.\n",
    "        '''\n",
    "        stateDistOut_ar=np.empty(len(self.stateIndex_ls))\n",
    "        previousStateOut_ls=[0]*len(self.stateIndex_ls)\n",
    "        \n",
    "        # For each row in the transition matrix:\n",
    "        for (i, row) in enumerate(self.logTransitionMatrix_ar):\n",
    "\n",
    "            # multiply (logged) each of the transition probabilities\n",
    "            # by the probability of being in that state\n",
    "            calculateTransitions_ar=stateIn_ms.get_log_current_state_distribution() + \\\n",
    "                                    self.logTransitionMatrix_ar.transpose()[i]\n",
    "            \n",
    "            # Find the index of the largest value (most probable transition) \n",
    "            argmax_i=np.argmax(calculateTransitions_ar)\n",
    "\n",
    "            # and add that probability and the previous state\n",
    "            # to the output values\n",
    "            stateDistOut_ar[i]=calculateTransitions_ar[argmax_i]\n",
    "            previousStateOut_ls[i]=argmax_i\n",
    "            \n",
    "        # return {'logdist':stateDistOut_ar, \n",
    "        #         'prevstates': previousStateOut_ls}\n",
    "\n",
    "        return MarkovState(stateIn_ms.get_index(),\n",
    "                           stateDistOut_ar,\n",
    "                           stateIn_ms.get_path_list() + [previousStateOut_ls])\n",
    "\n",
    "    def apply(self, stateIn_ms, steps=1):\n",
    "        '''\n",
    "        Takes an input MarkovState, and returns the output\n",
    "        MarkovState following steps applications.\n",
    "        \n",
    "        Can also take a list of states as an alternative to\n",
    "        the input MarkovState, in which case it will be \n",
    "        converted as necessary.\n",
    "\n",
    "        Both stateIn_ar and transitionIn_ar are expressed as logs.\n",
    "        \n",
    "        TODO: Raise an error if indices don't match, or if a\n",
    "              list is input which contains nonexistent states.\n",
    "        '''\n",
    "        \n",
    "        # First, if the given argument is not a MarkovState,\n",
    "        # generate one based on the input\n",
    "        if not isinstance(stateIn_ms, MarkovState):\n",
    "            stateIn_ms=self.create_markov_state(stateIn_ms)\n",
    "    \n",
    "        # Next, let's assume that we're only doing one step\n",
    "        # at the moment\n",
    "        \n",
    "        stateOut_ms=stateIn_ms\n",
    "        \n",
    "        for i in range(steps):\n",
    "            stateOut_ms=self.apply_1(stateOut_ms)\n",
    "        \n",
    "        return stateOut_ms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
