{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text transitioner. Attempt 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the same approach as the previous example to do a stepwise merging of Markov models, but I'll have a go with some real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, I'll use some text: let's see if we can transition Sherlock Holmes into, say, the King James bible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need the texts. I won't bother trying to work with individual sentences at the moment; I'll just treat it all as one huge block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Sherlock is here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/holmes/holmes.txt') as fIn:\n",
    "    holmesText_txt=fIn.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't want to spend the next month writing new NLP tools, so let's prepare it with nltk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holmesTokens_ls=nltk.tokenize.word_tokenize(holmesText_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenPairs_ls=[(holmesTokens_ls[i], holmesTokens_ls[i+1]) for i in range(len(holmesTokens_ls)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('and', 'if')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenPairs_ls[374676]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the moment of truth... will this let us create a Markov model, or are we going to run out of memory??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import markovmodels as mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "holmes_mm=mm.MarkovModel(tokenPairs_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that was taking rather too long... Let's try with the first 10,000 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenPairs_ls=[(holmesTokens_ls[i], holmesTokens_ls[i+1]) for i in range(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holmes_mm=mm.MarkovModel(tokenPairs_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that seems OK. So what's the most likely path from 'scientific' to 'Watson' in, say, 20 steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=holmes_mm.apply(['scientific'], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scientific',\n",
       " 'for',\n",
       " '?',\n",
       " \"''\",\n",
       " '``',\n",
       " 'What',\n",
       " 'John',\n",
       " 'Rance',\n",
       " 'Had',\n",
       " 'To',\n",
       " 'Tell',\n",
       " 'Our',\n",
       " 'Advertisement',\n",
       " 'Brings',\n",
       " 'A',\n",
       " 'Continuation',\n",
       " 'Of',\n",
       " 'Utah',\n",
       " 'John',\n",
       " 'H.',\n",
       " 'Watson']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.most_likely_path('Watson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same for the bible. We'll just use 10,000 tokens again. In this case, I'll also remove all the chapter:verse numbers too; so any occurrence of \\d+\\:\\d+ can be removed. Can use re.sub for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/bible/kingJamesBible.txt') as fIn:\n",
    "    bibleText_txt=re.sub('\\d+:\\d+', ' ', fIn.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibleTokens_ls=nltk.tokenize.word_tokenize(bibleText_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenPairs_ls=[(bibleTokens_ls[i], bibleTokens_ls[i+1]) for i in range(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bible_mm=mm.MarkovModel(tokenPairs_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=bible_mm.apply('Adam', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'window',\n",
       " 'shalt',\n",
       " 'take',\n",
       " 'any',\n",
       " 'more',\n",
       " 'subtil',\n",
       " 'than',\n",
       " 'any',\n",
       " 'more',\n",
       " 'subtil',\n",
       " 'than',\n",
       " 'any',\n",
       " 'more',\n",
       " 'subtil',\n",
       " 'than',\n",
       " 'any',\n",
       " 'beast',\n",
       " 'of',\n",
       " 'the',\n",
       " 'father']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.most_likely_path('father')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so 1-grams aren't great, but we can extend them to something bigger and better shortly. For the moment, let's just try merging these two texts. So what happens if we try to go from 'Holmes' to 'lord' in 20 steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Starting with a MM in holmes_mm\n",
    "# A second MM in bible_mm\n",
    "# A number of steps in numSteps_i\n",
    "\n",
    "numSteps_i=20\n",
    "\n",
    "# Start with an initial state, from 100% MM1. Here, use 'Holmes':\n",
    "\n",
    "merged_mm=mm.merge(holmes_mm, bible_mm, 1)\n",
    "state_ms=merged_mm.apply(['Holmes'])\n",
    "\n",
    "# Now do the rest of the cases:\n",
    "\n",
    "for weighting in reversed([x/numSteps_i for x in range(numSteps_i)]):\n",
    "    merged_mm=mm.merge(holmes_mm, bible_mm, weighting)\n",
    "    state_ms=merged_mm.apply(state_ms)\n",
    "    print(weighting)\n",
    "\n",
    "# And find most likely path to 'father':\n",
    "state_ms.most_likely_path('father')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
